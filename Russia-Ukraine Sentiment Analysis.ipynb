{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russia-Ukraine War Sentiment Analysis on Tweets\n",
    "On 23rd February, Russia announced special military operation on Ukraine. This geopolitical incident has been put under the limelight. As people gather on social media to express their opinion on the incident, it will be insightful to analyse their sentiment in an attempt to understand the public opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import yaml\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting tweets\n",
    "We use Tweepy which is built on Twitter API to collect tweets. Basic data cleaning is done on data, such as removing URL to minimise its effect on extracting the sentiment of user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as file:\n",
    "    keys = yaml.safe_load(file)\n",
    "    consumer_key = keys['search_tweets_api']['consumer_key']\n",
    "    consumer_secret = keys['search_tweets_api']['consumer_secret']\n",
    "    access_token = keys['search_tweets_api']['access_token']\n",
    "    access_token_secret = keys['search_tweets_api']['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth():\n",
    "    try:\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    except:\n",
    "        print('An error occurred during the authentication')\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove URL\n",
    "def remove_url(txt):\n",
    "    return ' '.join(re.sub('([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', '', txt).split())\n",
    "\n",
    "# function to remove time\n",
    "def remove_time(datetime):\n",
    "    return str(datetime).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_hashtag(api, date_until, words):\n",
    "    df = pd.DataFrame(columns=['id', 'created_at', 'username', 'location', 'following', \n",
    "                               'followers', 'retweetcount', 'text']) \n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=words, lang='en', until=date_until, tweet_mode='extended').items() \n",
    "    list_tweets = [tweet for tweet in tweets] \n",
    "         \n",
    "    for tweet in list_tweets: \n",
    "        id = tweet.id\n",
    "        created_at = remove_time(tweet.created_at)\n",
    "        username = tweet.user.screen_name \n",
    "        location = tweet.user.location \n",
    "        following = tweet.user.friends_count \n",
    "        followers = tweet.user.followers_count  \n",
    "        retweetcount = tweet.retweet_count \n",
    "\n",
    "        try: \n",
    "            text = tweet.retweeted_status.full_text \n",
    "        except AttributeError: \n",
    "            text = tweet.full_text \n",
    "        text = remove_url(text)\n",
    "  \n",
    "        tweets = [id, created_at, username, location, following, \n",
    "                     followers, retweetcount, text] \n",
    "\n",
    "        df.loc[len(df)] = tweets \n",
    "          \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 3\n",
      "Rate limit reached. Sleeping for: 851\n",
      "Rate limit reached. Sleeping for: 851\n",
      "Rate limit reached. Sleeping for: 850\n",
      "Rate limit reached. Sleeping for: 853\n"
     ]
    }
   ],
   "source": [
    "api = auth()\n",
    "words = 'Ukraine Russia -filter:retweets'\n",
    "date_until = '2022-02-25'\n",
    "df = search_by_hashtag(api, date_until, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "### Microsoft Azure\n",
    "We adopt Text Analytics in Azure Cognitive Services to obtain the sentiment score of tweets. The API can ouput confidence scores of the text being postive, neutral and negative respectively. For consistency and easier understanding, we will map the scores into a composite score in range [-1. 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    with open('config.yaml') as file:\n",
    "        keys = yaml.safe_load(file)\n",
    "        key = keys['azure']['subscription_key']\n",
    "        endpoint = keys['azure']['endpoint']\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for detecting sentiment in text\n",
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = list(df['text'])\n",
    "    polarity = []\n",
    "    azure_class = []\n",
    "    # For loop is used to bypass the batch request limit\n",
    "    for document in documents:\n",
    "        response = client.analyze_sentiment(documents=[document])[0]\n",
    "        azure_class.append(response.sentiment)\n",
    "        polarity.append(0 + response.confidence_scores.positive - response.confidence_scores.negative)\n",
    "    df['azure_polar'] = polarity\n",
    "    df['azure_class'] = azure_class\n",
    "\n",
    "client = authenticate_client()      \n",
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob\n",
    "Textblob is an open-source python library for processing textual data. It can evaluate both polarity and subjectivity in text. The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_objects = [TextBlob(tweet) for tweet in list(df['text'])]\n",
    "blob_polar = [tweet.sentiment.polarity for tweet in sentiment_objects]\n",
    "blob_subj = [tweet.sentiment.subjectivity for tweet in sentiment_objects]\n",
    "df['blob_polar'] = blob_polar\n",
    "df['blob_subj'] = blob_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare the sentiment scores rated by TextBlob and Azure respectively. It can be seen from the figure that Azure has a wider spectrum of sentiment, suggesting that it uses a more advanced algorithm to analyse the sentiment in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "df.hist(column='blob_polar', bins=[-1, -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1], ax=ax1)\n",
    "ax1.set_title('Sentiments analysed by TextBlob')\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "df.hist(column='azure_polar', bins=[-1, -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1], ax=ax2)\n",
    "ax1.set_title('Sentiments analysed by Azure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the sentiment of tweets, we can see a general trend towards positive sentiment, which can also be seen in the sentiment classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['azure_class'].value_counts().plot(kind='bar', title='Sentiment Class of Tweets on Ukraine-Russia War')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is counterintuitive to the common belief that war should lead to negative sentiment. Therefore, we examine some of the tweets classified as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive = df[df['azure_class'] == 'positive']\n",
    "postive.head()['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the examples, we can see that these tweets contain [ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we can examine the subjectivity of tweets. It can be seen that most users are subjective, which is in line with the nature of social media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='blob_subj', bins=[0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1], title='Subjectivity from Tweets on Ukraine-Russia War')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4486cc46800a3a36dbbddfd8b12a33d5293b2126d0bd638d95bed74d24a9d28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
